{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Problem"],"metadata":{"id":"PDZxOtCZt5VU"}},{"cell_type":"markdown","source":["$$f(w_1, w_2) = 0.1w_1^2 + 2w_2^2 \\;\\;\\;\\;\\;\\;\\;(1)$$ "],"metadata":{"id":"Z7esFCIXuNXS"}},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"_IAVg99F9N0y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### RMSprop"],"metadata":{"id":"HXAY82X82mDx"}},{"cell_type":"code","source":["def df_w(w):\n","    \"\"\"\n","    Thực hiện tính gradient của dw1 và dw2\n","    Arguments:\n","    W -- np.array [w1, w2]\n","    Returns:\n","    dW -- np.array [dw1, dw2], array chứa giá trị đạo hàm theo w1 và w2 \n","    \"\"\"\n","    #################### YOUR CODE HERE ####################\n","    \n","\n","    dW = \n","    ########################################################\n","    \n","    return dW"],"metadata":{"id":"uai1hzbWuNaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def RMSProp(W, dW, lr, S, gamma):\n","    \"\"\"\n","    Thực hiện thuật tóan RMSProp để update w1 và w2\n","    Arguments:\n","    W -- np.array: [w1, w2]\n","    dW -- np.array: [dw1, dw2], array chứa giá trị đạo hàm theo w1 và w2 \n","    lr -- float: learning rate \n","    S -- np.array: [s1, s2] Exponentially weighted averages bình phương gradients\n","    gamma -- float: hệ số long-range average\n","    Returns:\n","    W -- np.array: [w1, w2] w1 và w2 sau khi đã update\n","    S -- np.array: [s1, s2] Exponentially weighted averages bình phương gradients sau khi đã cập nhật\n","    \"\"\"\n","    epsilon = 1e-6\n","    #################### YOUR CODE HERE ####################\n","    \n","    S =\n","\n","    W = \n","    ########################################################\n","    return W, S"],"metadata":{"id":"ws1QcU-o3NPi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_p1(optimizer, lr, epochs):\n","    \"\"\"\n","    Thực hiện tìm điểm minimum của function (1) dựa vào thuật toán \n","    được truyền vào từ optimizer\n","    Arguments:\n","    optimize : function thực hiện thuật toán optimization cụ thể\n","    lr -- float: learning rate \n","    epochs -- int: số lượng lần (epoch) lặp để tìm điểm minimum \n","    Returns:\n","    results -- list: list các cặp điểm [w1, w2] sau mỗi epoch (mỗi lần cập nhật)\n","    \"\"\"\n","    # initial\n","    W = np.array([-5, -2], dtype=np.float32)\n","    S = np.array([0, 0], dtype=np.float32)\n","    results = [W]\n","    #################### YOUR CODE HERE ####################\n","    # Tạo vòng lặp theo số lần epochs\n","    # tìm gradient dW gồm dw1 và dw2\n","    # dùng thuật toán optimization cập nhật w1, w2, s1, s2\n","    # append cặp [w1, w2] vào list results\n","\n","    \n","    ########################################################\n","    return results"],"metadata":{"id":"QA_czueo4bz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_p1(RMSProp, lr=0.3, epochs=30)"],"metadata":{"id":"eGVlk8pi4kM5"},"execution_count":null,"outputs":[]}]}