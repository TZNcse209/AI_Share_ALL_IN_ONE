{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Problem"],"metadata":{"id":"PDZxOtCZt5VU"}},{"cell_type":"markdown","source":["$$f(w_1, w_2) = 0.1w_1^2 + 2w_2^2 \\;\\;\\;\\;\\;\\;\\;(1)$$ "],"metadata":{"id":"Z7esFCIXuNXS"}},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"_IAVg99F9N0y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### GD"],"metadata":{"id":"oRzDf03x2JqM"}},{"cell_type":"code","source":["def df_w(W):\n","    \"\"\"\n","    Thực hiện tính gradient của dw1 và dw2\n","    Arguments:\n","    W -- np.array [w1, w2]\n","    Returns:\n","    dW -- np.array [dw1, dw2], array chứa giá trị đạo hàm theo w1 và w2 \n","    \"\"\"\n","    #################### YOUR CODE HERE ####################\n","    \n","\n","    dW = \n","    ########################################################\n","    \n","    return dW"],"metadata":{"id":"uai1hzbWuNaK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sgd(W, dW, lr):\n","    \"\"\"\n","    Thực hiện thuật tóa Gradient Descent để update w1 và w2\n","    Arguments:\n","    W -- np.array: [w1, w2]\n","    dW -- np.array: [dw1, dw2], array chứa giá trị đạo hàm theo w1 và w2 \n","    lr -- float: learning rate \n","    Returns:\n","    W -- np.array: [w1, w2] w1 và w2 sau khi đã update\n","    \"\"\"\n","    #################### YOUR CODE HERE ####################\n","    \n","\n","    W = \n","    ########################################################\n","    return W "],"metadata":{"id":"634hfieBwwza"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_p1(optimizer, lr, epochs):\n","    \"\"\"\n","    Thực hiện tìm điểm minimum của function (1) dựa vào thuật toán \n","    được truyền vào từ optimizer\n","    Arguments:\n","    optimize : function thực hiện thuật toán optimization cụ thể\n","    lr -- float: learning rate \n","    epoch -- int: số lượng lần (epoch) lặp để tìm điểm minimum \n","    Returns:\n","    results -- list: list các cặp điểm [w1, w2] sau mỗi epoch (mỗi lần cập nhật)\n","    \"\"\"\n","\n","    # initial point\n","    W = np.array([-5, -2], dtype=np.float32)\n","    # list of results\n","    results = [W]\n","    #################### YOUR CODE HERE ####################\n","    # Tạo vòng lặp theo số lần epochs\n","    # tìm gradient dW gồm dw1 và dw2\n","    # dùng thuật toán optimization cập nhật w1 và w2\n","    # append cặp [w1, w2] vào list results\n","\n","    \n","    ########################################################\n","    return results"],"metadata":{"id":"jugR0jsA2-uC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_p1(sgd, lr=0.4, epochs=30)"],"metadata":{"id":"ZAAcmcEl8bQj"},"execution_count":null,"outputs":[]}]}