{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h-Np_BawFIlF","executionInfo":{"status":"ok","timestamp":1698845521328,"user_tz":-420,"elapsed":2380,"user":{"displayName":"Hiếu Vũ","userId":"16502689377345213736"}},"outputId":"2fb22a82-4a0c-44f4-cb61-3b6f11d2f7dc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["from collections import defaultdict\n","import math\n","\n","class AIVN_XGBoostRegressor():\n","    '''XGBoost from Scratch\n","    '''\n","\n","    def __init__(self, params, random_seed=None):\n","        self.params = defaultdict(lambda: None, params)\n","        self.subsample = self.params['subsample'] \\\n","            if self.params['subsample'] else 1.0\n","        self.learning_rate = self.params['learning_rate'] \\\n","            if self.params['learning_rate'] else 0.3\n","        self.base_prediction = self.params['base_score'] \\\n","            if self.params['base_score'] else 0.5\n","        self.max_depth = self.params['max_depth'] \\\n","            if self.params['max_depth'] else 5\n","        self.rng = np.random.default_rng(seed=random_seed)\n","\n","    def fit(self, X, y, objective, num_boost_round, verbose=False):\n","        current_predictions = self.base_prediction * np.ones(shape=y.shape)\n","        self.boosters = []\n","        for i in range(num_boost_round):\n","            gradients = objective.gradient(y, current_predictions)\n","            hessians = objective.hessian(y, current_predictions)\n","            sample_idxs = None if self.subsample == 1.0 \\\n","                else self.rng.choice(len(y),\n","                                     size=math.floor(self.subsample*len(y)),\n","                                     replace=False)\n","            booster = TreeBooster(X, gradients, hessians,\n","                                  self.params, self.max_depth, sample_idxs)\n","            current_predictions += self.learning_rate * booster.predict(X)\n","            self.boosters.append(booster)\n","            if verbose:\n","                print(f'[{i}] train loss = {objective.loss(y, current_predictions)}')\n","\n","    def predict(self, X):\n","        return (self.base_prediction + self.learning_rate\n","                * np.sum([booster.predict(X) for booster in self.boosters], axis=0))\n","\n","class TreeBooster():\n","\n","    def __init__(self, X, g, h, params, max_depth, idxs=None):\n","        self.params = params\n","        self.max_depth = max_depth\n","        assert self.max_depth >= 0, 'max_depth must be nonnegative'\n","        self.min_child_weight = params['min_child_weight'] \\\n","            if params['min_child_weight'] else 1.0\n","        self.reg_lambda = params['reg_lambda'] if params['reg_lambda'] else 1.0\n","        self.gamma = params['gamma'] if params['gamma'] else 0.0\n","        self.colsample_bynode = params['colsample_bynode'] \\\n","            if params['colsample_bynode'] else 1.0\n","        if isinstance(g, pd.Series): g = g.values\n","        if isinstance(h, pd.Series): h = h.values\n","        if idxs is None: idxs = np.arange(len(g))\n","        self.X, self.g, self.h, self.idxs = X, g, h, idxs\n","        self.n, self.c = len(idxs), X.shape[1]\n","        self.value = -g[idxs].sum() / (h[idxs].sum() + self.reg_lambda) # Eq (5)\n","        self.best_score_so_far = 0.\n","        if self.max_depth > 0:\n","            self._maybe_insert_child_nodes()\n","\n","    def _maybe_insert_child_nodes(self):\n","        for i in range(self.c): self._find_better_split(i)\n","        if self.is_leaf: return\n","        x = self.X.values[self.idxs,self.split_feature_idx]\n","        left_idx = np.nonzero(x <= self.threshold)[0]\n","        right_idx = np.nonzero(x > self.threshold)[0]\n","        self.left = TreeBooster(self.X, self.g, self.h, self.params,\n","                                self.max_depth - 1, self.idxs[left_idx])\n","        self.right = TreeBooster(self.X, self.g, self.h, self.params,\n","                                 self.max_depth - 1, self.idxs[right_idx])\n","\n","    @property\n","    def is_leaf(self): return self.best_score_so_far == 0.\n","\n","    def _find_better_split(self, feature_idx):\n","        x = self.X.values[self.idxs, feature_idx]\n","        g, h = self.g[self.idxs], self.h[self.idxs]\n","        sort_idx = np.argsort(x)\n","        sort_g, sort_h, sort_x = g[sort_idx], h[sort_idx], x[sort_idx]\n","        sum_g, sum_h = g.sum(), h.sum()\n","        sum_g_right, sum_h_right = sum_g, sum_h\n","        sum_g_left, sum_h_left = 0., 0.\n","\n","        for i in range(0, self.n - 1):\n","            g_i, h_i, x_i, x_i_next = sort_g[i], sort_h[i], sort_x[i], sort_x[i + 1]\n","            sum_g_left += g_i; sum_g_right -= g_i\n","            sum_h_left += h_i; sum_h_right -= h_i\n","            if sum_h_left < self.min_child_weight or x_i == x_i_next:continue\n","            if sum_h_right < self.min_child_weight: break\n","\n","            gain = 0.5 * ((sum_g_left**2 / (sum_h_left + self.reg_lambda))\n","                            + (sum_g_right**2 / (sum_h_right + self.reg_lambda))\n","                            - (sum_g**2 / (sum_h + self.reg_lambda))\n","                            ) - self.gamma/2 # Eq(7) in the xgboost paper\n","            if gain > self.best_score_so_far:\n","                self.split_feature_idx = feature_idx\n","                self.best_score_so_far = gain\n","                self.threshold = (x_i + x_i_next) / 2\n","\n","    def predict(self, X):\n","        return np.array([self._predict_row(row) for i, row in X.iterrows()])\n","\n","    def _predict_row(self, row):\n","        if self.is_leaf:\n","            return self.value\n","        child = self.left if row[self.split_feature_idx] <= self.threshold \\\n","            else self.right\n","        return child._predict_row(row)"],"metadata":{"id":"TcCTq7tyUGCs","executionInfo":{"status":"ok","timestamp":1698845521328,"user_tz":-420,"elapsed":6,"user":{"displayName":"Hiếu Vũ","userId":"16502689377345213736"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","class SquaredErrorObjective():\n","    def loss(self, y, pred): return np.mean((y - pred)**2)\n","    def gradient(self, y, pred): return pred - y\n","    def hessian(self, y, pred): return np.ones(len(y))"],"metadata":{"id":"zxkwHCs0VF0W","executionInfo":{"status":"ok","timestamp":1698845521328,"user_tz":-420,"elapsed":4,"user":{"displayName":"Hiếu Vũ","userId":"16502689377345213736"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","\n","#READ DATA\n","data = pd.read_csv(\"/content/drive/Othercomputers/My Laptop/Advanced/D-Learning/230915/Code - update/advertising.csv\")\n","\n","#X,y\n","X = data.iloc[:,:-1]\n","y = data.iloc[:,-1]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=100)"],"metadata":{"id":"-VtX4xEmHXML","executionInfo":{"status":"ok","timestamp":1698845521807,"user_tz":-420,"elapsed":482,"user":{"displayName":"Hiếu Vũ","userId":"16502689377345213736"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# from sklearn.datasets import fetch_california_housing\n","# from sklearn.model_selection import train_test_split\n","\n","# X, y = fetch_california_housing(as_frame=True, return_X_y=True)\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,\n","#                                                     random_state=43)"],"metadata":{"id":"Wv90gL7SV2TP","executionInfo":{"status":"ok","timestamp":1698845521807,"user_tz":-420,"elapsed":8,"user":{"displayName":"Hiếu Vũ","userId":"16502689377345213736"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["params = {\n","    'learning_rate': 0.1,\n","    'max_depth': 5,\n","    'subsample': 0.8,\n","    'reg_lambda': 1.5,\n","    'gamma': 0.0,\n","    'min_child_weight': 25,\n","    'base_score': 0.0,\n","    'tree_method': 'exact',\n","}\n","num_boost_round = 50\n","\n","# train the from-scratch XGBoost model\n","model_scratch = AIVN_XGBoostRegressor(params, random_seed=42)\n","model_scratch.fit(X_train, y_train, SquaredErrorObjective(), num_boost_round)\n"],"metadata":{"id":"Xq6LYVLpVTFD","executionInfo":{"status":"ok","timestamp":1698845522240,"user_tz":-420,"elapsed":440,"user":{"displayName":"Hiếu Vũ","userId":"16502689377345213736"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["pred_scratch = model_scratch.predict(X_test)\n","print(f'Our implementation: {SquaredErrorObjective().loss(y_test, pred_scratch)}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mAInh4MqV9U_","outputId":"acfaba5a-4628-4904-b5a9-7e08ed36a994","executionInfo":{"status":"ok","timestamp":1698845522241,"user_tz":-420,"elapsed":7,"user":{"displayName":"Hiếu Vũ","userId":"16502689377345213736"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Our implementation: 1.7017064684759806\n"]}]},{"cell_type":"code","source":["from xgboost import XGBRegressor\n","\n","model = XGBRegressor()\n","model.fit(X_train, y_train)\n","\n","pred_scratch = model.predict(X_test)\n","print(f'XGBRegressor Lib: {SquaredErrorObjective().loss(y_test, pred_scratch)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GMCb5pgfPAO8","outputId":"e4b76290-70f7-45f6-c36f-642b32eb7c68","executionInfo":{"status":"ok","timestamp":1698845522545,"user_tz":-420,"elapsed":310,"user":{"displayName":"Hiếu Vũ","userId":"16502689377345213736"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["XGBRegressor Lib: 1.0949672299526045\n"]}]}]}